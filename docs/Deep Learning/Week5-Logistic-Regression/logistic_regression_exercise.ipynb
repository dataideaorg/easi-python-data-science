{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Logistic Regression Exercise\n",
    "author: Juma Shafara\n",
    "date: \"2024-08-29\"\n",
    "keywords: [data science, data analysis, programming, dataidea]\n",
    "description: Programming for Data Science is a subject we’ve designed to explore the various programming components of data science.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Photo by DATAIDEA](../../assets/banner4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Week 5: Logistic Regression\n",
    "\n",
    "### 1. **Making Predictions in Logistic Regression**\n",
    "   - **Exercise:** Implement a logistic regression model to classify data into two classes. Use a synthetic dataset with two features and evaluate the model’s accuracy using confusion matrix.\n",
    "\n",
    "### 2. **Logistic Regression and Bad Initialization Values**\n",
    "   - **Exercise:** Train a logistic regression model with various initialization strategies. Analyze how different initial weights affect the convergence and performance of the model.\n",
    "\n",
    "### 3. **Cross Entropy Loss Function**\n",
    "   - **Exercise:** Implement the cross-entropy loss function from scratch for a logistic regression model. Compare its output with PyTorch’s built-in `torch.nn.CrossEntropyLoss` function.\n",
    "\n",
    "<!-- Newsletter -->\n",
    "<div class=\"newsletter\">\n",
    "<div class=\"newsletter-heading\">\n",
    "<h4><i class=\"bi bi-info-circle-fill\"></i> Don't Miss Any Updates!</h4>\n",
    "</div>\n",
    "<div class=\"newsletter-body\">\n",
    "<p>\n",
    "Before the last, I have a humble request, to be among the first to hear about future updates of the course materials, simply enter your email below, follow us on <a href=\"https://x.com/dataideaorg\"><i class=\"bi bi-twitter-x\"></i>\n",
    "(formally Twitter)</a>, or subscribe to our <a href=\"https://www.youtube.com/@dataidea-science\"><i class=\"bi bi-youtube\"></i> YouTube channel</a>.\n",
    "</p>\n",
    "<iframe class=\"newsletter-frame\" src=\"https://embeds.beehiiv.com/5fc7c425-9c7e-4e08-a514-ad6c22beee74?slim=true\" data-test-id=\"beehiiv-embed\" height=\"52\" frameborder=\"0\" scrolling=\"no\">\n",
    "</iframe>\n",
    "</div>\n",
    "</div>\n",
    "\n",
    "### 4. **Softmax Activation in 1 Dimension**\n",
    "   - **Exercise:** Implement the softmax activation function for a vector of logits in a 1D tensor. Use this function to convert raw model outputs into probabilities and interpret the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>What's on your mind? Put it in the comments!</h2>\n",
    "<script src=\"https://utteranc.es/client.js\"\n",
    "        repo=\"dataideaorg/dataidea-science\"\n",
    "        issue-term=\"pathname\"\n",
    "        theme=\"github-light\"\n",
    "        crossorigin=\"anonymous\"\n",
    "        async>\n",
    "</script>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
