{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "author: Juma Shafara\n",
        "date: \"2024-08-12\"\n",
        "title: Activation function and Maxpooling\n",
        "keywords: [Training Two Parameter, Mini-Batch Gradient Decent, Training Two Parameter Mini-Batch Gradient Decent]\n",
        "description: In this lab, you will learn two important components in building a convolutional neural network.\n",
        "---\n",
        "\n",
        "![Photo by DATAIDEA](../../assets/banner4.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "<h3>Objective for this Notebook<h3>    \n",
        "<h5> 1. Learn how to apply an activation function.</h5>\n",
        "<h5> 2. Learn about max pooling </h5>     \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Table of Contents\n",
        "In this lab, you will learn two important components in building a convolutional neural network. The first is applying an activation function, which is analogous to building a regular network. You will also learn about max pooling. Max pooling reduces the number of parameters and makes the network less susceptible to changes in the image. \n",
        "\n",
        "\n",
        "<li><a href=\"#ref0\">Activation Functions</a></li>\n",
        "\n",
        "<li><a href=\"#ref1\">Max Pooling</a></li>\n",
        "\n",
        "\n",
        "<br>\n",
        "<p></p>\n",
        "Estimated Time Needed: <strong>25 min</strong>\n",
        "</div>\n",
        "\n",
        "<hr>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- Newsletter -->\n",
        "<div class=\"newsletter\">\n",
        "<div class=\"newsletter-heading\">\n",
        "<h4><i class=\"bi bi-info-circle-fill\"></i> Don't Miss Any Updates!</h4>\n",
        "</div>\n",
        "<div class=\"newsletter-body\">\n",
        "<p>\n",
        "Before we continue, I have a humble request, to be among the first to hear about future updates of the course materials, simply enter your email below, follow us on <a href=\"https://x.com/dataideaorg\"><i class=\"bi bi-twitter-x\"></i>\n",
        "(formally Twitter)</a>, or subscribe to our <a href=\"https://www.youtube.com/@dataidea-science\"><i class=\"bi bi-youtube\"></i> YouTube channel</a>.\n",
        "</p>\n",
        "<iframe class=\"newsletter-frame\" src=\"https://embeds.beehiiv.com/5fc7c425-9c7e-4e08-a514-ad6c22beee74?slim=true\" data-test-id=\"beehiiv-embed\" height=\"52\" frameborder=\"0\" scrolling=\"no\">\n",
        "</iframe>\n",
        "</div>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import the following libraries:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch \n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy import ndimage, misc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"ref0\"></a>\n",
        "<h2>Activation Functions  </h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Just like a neural network, you apply an activation function to the activation map as shown in the following image:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter%206/6.1.3block_digram.png\" width=\"1000,\" align=\"center\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create a kernel and image as usual. Set the bias to zero: \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "OrderedDict([('weight',\n",
              "              tensor([[[[ 1.,  0., -1.],\n",
              "                        [ 2.,  0., -2.],\n",
              "                        [ 1.,  0., -1.]]]])),\n",
              "             ('bias', tensor([0.]))])"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conv = nn.Conv2d(in_channels=1, out_channels=1,kernel_size=3)\n",
        "Gx=torch.tensor([[1.0,0,-1.0],[2.0,0,-2.0],[1.0,0,-1.0]])\n",
        "conv.state_dict()['weight'][0][0]=Gx\n",
        "conv.state_dict()['bias'][0]=0.0\n",
        "conv.state_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[[0., 0., 1., 0., 0.],\n",
              "          [0., 0., 1., 0., 0.],\n",
              "          [0., 0., 1., 0., 0.],\n",
              "          [0., 0., 1., 0., 0.],\n",
              "          [0., 0., 1., 0., 0.]]]])"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image=torch.zeros(1,1,5,5)\n",
        "image[0,0,:,2]=1\n",
        "image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following image shows the image and kernel: \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter%206/6.1.3kernal_out.png\" width=\"500,\" align=\"center\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Apply convolution to the image: \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[[-4.,  0.,  4.],\n",
              "          [-4.,  0.,  4.],\n",
              "          [-4.,  0.,  4.]]]], grad_fn=<ConvolutionBackward0>)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Z=conv(image)\n",
        "Z"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Apply the activation function to the activation map. This will apply the activation function to each element in the activation map.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[[0., 0., 4.],\n",
              "          [0., 0., 4.],\n",
              "          [0., 0., 4.]]]], grad_fn=<ReluBackward0>)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A=torch.relu(Z)\n",
        "A"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[[0., 0., 4.],\n",
              "          [0., 0., 4.],\n",
              "          [0., 0., 4.]]]], grad_fn=<ReluBackward0>)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "relu = nn.ReLU()\n",
        "relu(Z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The process is summarized in the the following figure. The Relu function is applied to each element. All the elements less than zero are mapped to zero. The remaining components do not change.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter%206/6.2.3_block_example.gif\" width=\"1000,\" align=\"center\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"ref1\"></a>\n",
        "<h2>Max Pooling </h2>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Consider the following image: \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[[ 1.,  2.,  3., -4.],\n",
              "          [ 0.,  2., -3.,  0.],\n",
              "          [ 0.,  2.,  3.,  1.],\n",
              "          [ 0.,  0.,  0.,  0.]]]])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "image1=torch.zeros(1,1,4,4)\n",
        "image1[0,0,0,:]=torch.tensor([1.0,2.0,3.0,-4.0])\n",
        "image1[0,0,1,:]=torch.tensor([0.0,2.0,-3.0,0.0])\n",
        "image1[0,0,2,:]=torch.tensor([0.0,2.0,3.0,1.0])\n",
        "\n",
        "image1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Max pooling simply takes the maximum value in each region. Consider the following image. For the first region, max pooling simply takes the largest element in a yellow region.   \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter%206/6.1.3maxpool_1.png\" width=\"500,\" align=\"center\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The region shifts, and the process is repeated. The process is similar to convolution and is demonstrated in the following figure:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter%206/6.1.3_max_pool_animation.gif\" width=\"500,\" align=\"center\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create a maxpooling object in 2d as follows and perform max pooling as follows:  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[[2., 3., 3.],\n",
              "          [2., 3., 3.],\n",
              "          [2., 3., 3.]]]])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max1=torch.nn.MaxPool2d(2,stride=1)\n",
        "max1(image1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If the stride is set to None (its defaults setting), the process will simply take the maximum in a prescribed area and shift over accordingly as shown in the following figure:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter%206/6.1.3_max_pool_animation_2.gif\" width=\"500,\" align=\"center\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here's the code in Pytorch:  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h2>What's on your mind? Put it in the comments!</h2>\n",
        "<script src=\"https://utteranc.es/client.js\"\n",
        "        repo=\"dataideaorg/dataidea-science\"\n",
        "        issue-term=\"pathname\"\n",
        "        theme=\"github-light\"\n",
        "        crossorigin=\"anonymous\"\n",
        "        async>\n",
        "</script>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
